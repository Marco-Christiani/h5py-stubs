from collections.abc import Iterable, Iterator, Sequence
from typing import Literal

import numpy as np
from _typeshed import StrOrBytesPath
from h5py.h5d import DatasetID
from h5py.h5p import PropDAID, PropDCID
from optype import numpy as onpt
from typing_extensions import Self  # noqa: UP035

from .base import Empty, HLObject
from .datatype import Datatype
from .dims import DimensionManager
from .group import Group
from .vds import VDSmap

type _DType = np.dtype[np.generic]
type _AnyShape = tuple[int, ...]
type _AnyArray = np.ndarray[_AnyShape, _DType]

def make_new_dset(
    parent: Group,
    shape: int | Iterable[int] | None = None,
    dtype: onpt.AnyDType | Datatype | None = None,
    data: _AnyArray | Empty | None = None,
    name: bytes | None = None,
    chunks: int | bool | tuple[int, ...] | None = None,
    compression: Literal["gzip", "lzf", "szip"] | None = None,
    shuffle: bool | None = None,
    fletcher32: bool | None = None,
    maxshape: int | tuple[int, ...] | None = None,
    compression_opts: int | tuple[int, int] | None = None,
    fillvalue: object | None = None,
    scaleoffset: int | bool | None = None,
    track_times: bool = False,
    external: Sequence[tuple[str, int, int]] | StrOrBytesPath | None = None,
    track_order: bool | None = None,
    dcpl: PropDCID | None = None,
    dapl: PropDAID | None = None,
    efile_prefix: bytes | None = None,
    virtual_prefix: bytes | None = None,
    allow_unknown_filter: bool = False,
    rdcc_nslots: int | None = None,
    rdcc_nbytes: int | None = None,
    rdcc_w0: float | None = None,
    *,
    fill_time: Literal["alloc", "never", "ifset"] | None = None,
) -> DatasetID: ...
def open_dset(
    parent: Group,
    name: bytes,
    dapl: PropDAID | None = None,
    efile_prefix: bytes | None = None,
    virtual_prefix: bytes | None = None,
    rdcc_nslots: int | None = None,
    rdcc_nbytes: int | None = None,
    rdcc_w0: float | None = None,
    **kwds: object,
) -> DatasetID: ...
def readtime_dtype(basetype: _DType, names: Sequence[str]) -> _DType: ...

class AstypeWrapper:
    def __init__(self, dset: Dataset, dtype: onpt.AnyDType) -> None: ...
    def __getitem__(self, args: object) -> _AnyArray | Empty | FieldsWrapper: ...
    def __len__(self) -> int: ...
    def __array__(self, dtype: onpt.AnyDType | None = None, copy: bool = True) -> _AnyArray: ...

class AsStrWrapper:
    def __init__(self, dset: Dataset, encoding: str | None, errors: str = "strict") -> None: ...
    def __getitem__(self, args: object) -> str | onpt.AnyStrArray: ...
    def __len__(self) -> int: ...
    def __array__(self, dtype: onpt.AnyDType | None = None, copy: bool = True) -> _AnyArray: ...

class FieldsWrapper:
    extract_field: str | None = None
    def __init__(self, dset: Dataset, prior_dtype: _DType, names: Sequence[str]) -> None: ...
    def __array__(self, dtype: onpt.AnyDType | None = None, copy: bool = True) -> _AnyArray: ...
    def __getitem__(self, args: object) -> _AnyArray | Empty | FieldsWrapper: ...
    def __len__(self) -> int: ...

class CollectiveContext:
    def __init__(self, dset: Dataset) -> None: ...
    def __enter__(self) -> None: ...
    def __exit__(self, *args: object) -> None: ...

class ChunkIterator:
    def __init__(self, dset: Dataset, source_sel: slice | tuple[slice, ...] | None = None) -> None: ...
    def __iter__(self) -> Self: ...
    def __next__(self) -> tuple[slice, ...]: ...

class Dataset(HLObject):
    def astype(self, dtype: onpt.AnyDType) -> AstypeWrapper: ...
    def asstr(self, encoding: str | None = None, errors: str = "strict") -> AsStrWrapper: ...
    def fields(self, names: Sequence[str], *, _prior_dtype: _DType = ...) -> FieldsWrapper: ...
    @property
    def collective(self) -> CollectiveContext: ...
    @property
    def dims(self) -> DimensionManager: ...
    @property
    def ndim(self) -> int: ...
    @property
    def shape(self) -> tuple[int, ...]: ...
    @shape.setter
    def shape(self, shape: tuple[int, ...]) -> None: ...
    @property
    def size(self) -> int | None: ...
    @property
    def nbytes(self) -> int: ...
    @property
    def dtype(self) -> _DType: ...
    @property
    def chunks(self) -> tuple[int, ...] | None: ...
    @property
    def compression(self) -> Literal["gzip", "lzf", "szip"] | None: ...
    @property
    def compression_opts(self) -> int | tuple[int, int] | None: ...
    @property
    def shuffle(self) -> bool: ...
    @property
    def fletcher32(self) -> bool: ...
    @property
    def scaleoffset(self) -> int | None: ...
    @property
    def external(self) -> Sequence[tuple[str, int, int]] | None: ...
    @property
    def maxshape(self) -> tuple[int | None, ...] | None: ...
    @property
    def fillvalue(self) -> object: ...
    def __init__(self, bind: DatasetID, *, readonly: bool = False) -> None: ...
    def resize(self, size: int | tuple[int, ...], axis: int | None = None) -> None: ...
    def __len__(self) -> int: ...
    def len(self) -> int: ...
    def __iter__(self) -> Iterator[object]: ...
    def iter_chunks(self, sel: slice | tuple[slice, ...] | None = None) -> ChunkIterator: ...
    def __getitem__(self, args: object, new_dtype: onpt.AnyDType | None = None) -> _AnyArray | FieldsWrapper | Empty: ...
    def __setitem__(self, args: object, val: object) -> None: ...
    def read_direct(self, dest: _AnyArray, source_sel: object | None = None, dest_sel: object | None = None) -> None: ...
    def write_direct(self, source: _AnyArray, source_sel: object | None = None, dest_sel: object | None = None) -> None: ...
    def __array__(self, dtype: onpt.AnyDType | None = None, copy: bool = True) -> _AnyArray: ...
    def refresh(self) -> None: ...
    def flush(self) -> None: ...
    @property
    def is_virtual(self) -> bool: ...
    def virtual_sources(self) -> Sequence[VDSmap]: ...
    def make_scale(self, name: str = "") -> None: ...
    @property
    def is_scale(self) -> bool: ...
